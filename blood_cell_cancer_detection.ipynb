{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKeVGxZ5GG6o"
      },
      "source": [
        "# Import needed modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeMcAy_5GG6s"
      },
      "outputs": [],
      "source": [
        "# import system libs\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "import itertools\n",
        "from PIL import Image\n",
        "\n",
        "# import data handling tools\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# import Deep learning Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "# from tf.keras.applications.efficientnet.EfficientNetB3\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('modules loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA_gwvwnGG6v"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4reLHLHabWD"
      },
      "source": [
        "### **Read data and store it in dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXeOTCUuQqP7"
      },
      "outputs": [],
      "source": [
        "# Generate data paths with labels\n",
        "data_dir = '/content/bloodcells_dataset'\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(data_dir)\n",
        "for fold in folds:\n",
        "    foldpath = os.path.join(data_dir, fold)\n",
        "    filelist = os.listdir(foldpath)\n",
        "    if fold in ['ig', 'neutrophil']:\n",
        "        continue\n",
        "    for file in filelist:\n",
        "        fpath = os.path.join(foldpath, file)\n",
        "\n",
        "        filepaths.append(fpath)\n",
        "        labels.append(fold)\n",
        "\n",
        "# Concatenate data paths with labels into one dataframe\n",
        "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
        "Lseries = pd.Series(labels, name='labels')\n",
        "df = pd.concat([Fseries, Lseries], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPtOSZAxQqP8"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md66WxGKQqP9"
      },
      "source": [
        "### **Split dataframe into train, valid, and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zpVQA-VQqP-"
      },
      "outputs": [],
      "source": [
        "# train dataframe\n",
        "train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)\n",
        "\n",
        "# valid and test dataframe\n",
        "valid_df, test_df = train_test_split(dummy_df,  train_size= 0.6, shuffle= True, random_state= 123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eipUlTaQqQA"
      },
      "source": [
        "### **Create image data generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNhtZhGHQqQA"
      },
      "outputs": [],
      "source": [
        "# crobed image size\n",
        "batch_size = 16\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "tr_gen = ImageDataGenerator()\n",
        "ts_gen = ImageDataGenerator()\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= False, batch_size= batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5xvHAW8QqQB"
      },
      "source": [
        "### **Show sample from train data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4VqHbSnQqQC"
      },
      "outputs": [],
      "source": [
        "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
        "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
        "images, labels = next(train_gen)      # get a batch size samples from the generator\n",
        "\n",
        "plt.figure(figsize= (20, 20))\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    image = images[i] / 255       # scales data to range (0 - 255)\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])  # get image index\n",
        "    class_name = classes[index]   # get class of image\n",
        "    plt.title(class_name, color= 'blue', fontsize= 12)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57eDFl3oGG65"
      },
      "source": [
        "# **Model Structure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wvOKjeRGG65"
      },
      "source": [
        "#### **Generic Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDT4CV15abWT"
      },
      "outputs": [],
      "source": [
        "# Create Model Structure\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n",
        "\n",
        "# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n",
        "# we will use efficientnetb3 from EfficientNet family.\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n",
        "# base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
        "    Dense(256, kernel_regularizer= regularizers.l2(l2= 0.016), activity_regularizer= regularizers.l1(0.006),\n",
        "                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n",
        "    Dropout(rate= 0.45, seed= 123),\n",
        "    Dense(class_count, activation= 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap89fjdxGG67"
      },
      "source": [
        "#### **Train model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uk3BTERGG67"
      },
      "outputs": [],
      "source": [
        "epochs = 10   # number of all epochs in training\n",
        "\n",
        "history = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen,\n",
        "                    validation_steps= None, shuffle= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNKq6ebOGG67"
      },
      "source": [
        "#### **Display model performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0Bj0Sp_GG68"
      },
      "outputs": [],
      "source": [
        "# Define needed variables\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ff430fyKC-RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MySXhfAJGG68"
      },
      "source": [
        "# **Evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSKDkyXXGG68"
      },
      "outputs": [],
      "source": [
        "ts_length = len(test_df)\n",
        "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "\n",
        "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
        "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
        "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Validation Loss: \", valid_score[0])\n",
        "print(\"Validation Accuracy: \", valid_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l-DABtFGG68"
      },
      "source": [
        "# **Get Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDFj7MZdGG69"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_gen)\n",
        "y_pred = np.argmax(preds, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_path = '/content/Screenshot 2025-09-10 192242.png'\n",
        "img = image.load_img(img_path, target_size=img_size)\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "# Get the class name from the index\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "print(f\"The model predicts this image is a: {predicted_class_name}\")\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted: {predicted_class_name}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qRA_KUwG6z0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJscUTF6GG69"
      },
      "source": [
        "#### **Confusion Matrics and Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAjW4IBEQqQM"
      },
      "outputs": [],
      "source": [
        "g_dict = test_gen.class_indices\n",
        "classes = list(g_dict.keys())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_gen.classes, y_pred)\n",
        "\n",
        "plt.figure(figsize= (10, 10))\n",
        "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation= 45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQR-UlD6GG69"
      },
      "outputs": [],
      "source": [
        "# Classification report\n",
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsIK5v0lGG69"
      },
      "source": [
        "#### **Save model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiHQzq8XGG6-"
      },
      "outputs": [],
      "source": [
        "#Save the model\n",
        "model.save('Bloods.h5')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef231b04"
      },
      "source": [
        "!unzip '/content/archive (1).zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ace5ce"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e69c4456"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}